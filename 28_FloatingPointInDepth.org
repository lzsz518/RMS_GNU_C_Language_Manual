#+title: 深入浮点数

* 浮点数的呈现方式

将数字存储为浮点数允许表示具有分数值的数字，其范围大于硬件整数的范围。浮点数由一个符号位、
一个尾数（也称为尾数）、以及一个固定基数的幂组成。GNU C 使用IEEE 754-2008《浮点运算标准》规定的浮点表示法。

IEEE 754-2008 规范定义了五种不同大小的基本二进制浮点格式：16位、32位、64位、128位和256位。
其中，32位、64位和128位的格式用于标准C类型 float、double 和 long double。
GNU C 在某些平台上支持16位浮点类型 _Float16，但不支持256位浮点类型。

每种格式都将浮点数编码为一个符号位。接下来是一个指数，指定了2的幂（带有一个固定偏移）。然后是尾数。

尾数的第一个位，在二进制点之前，始终为1，因此无需将其存储在内存中。它称为隐藏位，因为它在计算机本身使用的浮点数中不可见。

所有这些浮点格式都是带符号的幂表示法，因此+0和-0是不同的值。

除了IEEE 754格式的128位浮点数之外，GNU C 还提供了由一对64位浮点数组成的格式。
这种格式不具备IEEE 128位格式的完整指数范围，但在底层硬件平台不支持该格式时很有用。

* 浮点数的规格

标准库头文件 float.h 定义了一些常量，用于描述平台对浮点类型 float、double 和 long double 的实现。这些常量包括：

#+begin_src c
FLT_MIN

DBL_MIN

LDBL_MIN
#+end_src

它们定义了可以用该类型表示的最小规格化正浮点值。

#+begin_src c
FLT_HAS_SUBNORM

DBL_HAS_SUBNORM

LDBL_HAS_SUBNORM
#+end_src

它们定义了浮点类型是否支持次正规（或“非规格化”）数，参见非规格化数。

#+begin_src c
FLT_TRUE_MIN

DBL_TRUE_MIN

LDBL_TRUE_MIN
#+end_src

它们定义了可以用该类型表示的最小正值（包括次正规值）。

#+begin_src c
FLT_MAX

DBL_MAX

LDBL_MAX
#+end_src

它们定义了可以用该类型表示的最大值。

#+begin_src c
FLT_DECIMAL_DIG

DBL_DECIMAL_DIG

LDBL_DECIMAL_DIG
#+end_src

它们定义了一个十进制数字 n 的数量，使得可以将任何可以用该类型表示的浮点数四舍五入为具有 n 位小数的浮点数，
然后再转换回来，而不会失去任何值的精度。

* 特殊的点数值


IEEE浮点数提供了一些特殊的值，它们不是普通的数字。

 * infinities(无限)

 +Infinities和-Infinty是两个不同的无限大值。它们是由诸如1 / 0、Infinity + Infinity、Infinity * Infinity、Infinity + finite
 等操作产生的，还可以由一个有限但大于最大可能值或小于最小可能值的结果产生。

 有关处理无穷大的更多信息，请参阅"处理无穷大"。

 * NaNs(非数值)

 有两个特殊的值，称为非数值（NaN）：安静的NaN（QNaN）和信号NaN（SNaN）。

 **QNaN** 由于在实数运算中其值未定义而产生，例如0 / 0、sqrt(-1)、Infinity - Infinity以及任何基本操作中的一个操作数是QNaN。

 **信号NaN（SNaN）** 旨在初始化未分配的存储空间，与QNaN不同，SNaN会引发一个中断，可以被软件处理程序捕获、诊断和报告。
 实际上，鲜有使用信号NaN，因为桌面和便携计算机中最常见的CPU未实现完整的IEEE 754标准，只提供了一种NaN，即安静的NaN。
 此外，编程语言标准需要几十年的时间来跟上IEEE 754标准的步伐，这些语言标准的实现在程序员愿意使用这些特性之前还需要额外的时间。

 要启用对信号NaN的支持，请使用GCC命令行选项`-fsignaling-nans`，但这是一个实验性功能，并且在每种情况下都可能无法按预期工作。

 NaN具有一个符号位，但其值毫无意义。

 有关处理NaN的更多信息，请参阅"处理NaN"。   

* 非规格化数

可能发生计算出的浮点值太小而无法表示的情况，例如当两个非常小的数相乘时。
结果被称为"下溢"。在IEEE 754标准出现之前，传统的行为是将结果设为零，并且可能在某种程序输出中报告下溢。

IEEE 754标准对于舍入是否在检测到浮点下溢和上溢之前发生或之后发生模糊不清，CPU设计者可以选择其中之一。

然而，与早期设计相比，该标准采用了一种不同寻常的方式，即当结果小于最小可规格化值（即前导尾数位为1的值）时，
放宽了规格化要求，允许前导零位，并逐渐丧失精度，直到尾数不再有位。这种现象称为"渐进下溢"，
它在数值计算中具有重要作用，尽管它会降低最终结果的精度。一些浮点设计允许您在编译时甚至在运行时选择下溢是渐进的还是突然变为零。
已进入渐进下溢区域的数字称为"次规格化数"。

您可以使用库函数 fesetround 和 fegetround 来设置和获取舍入模式。
舍入模式在 fenv.h 中定义（如果平台支持）：FE_UPWARD 用于朝正无穷舍入；
FE_DOWNWARD 用于朝负无穷舍入；FE_TOWARDZERO 用于朝零舍入；
FE_TONEAREST 用于舍入到最接近的可表示值，这是默认模式。除非有特殊需要，最好使用 FE_TONEAREST 模式。

* 无效优化

有符号零、无穷大和NaN使得程序员和编译器可能会放弃一些本来似乎很明显的优化：

 * x + 0 和 x - 0 当 x 为零时不同，因为结果取决于舍入规则。有关舍入规则的更多信息，请参阅"舍入"。
 * x * 0.0 与 0.0 不同，当 x 为无穷大、NaN 或负零时。
 * x / x 与 1.0 不同，当 x 为无穷大、NaN 或零时。
 * (x - y) 与 -(y - x) 不同，因为当操作数有限且相等时，一个计算为+0，另一个计算为-0。
 * x - x 与 0.0 不同，当 x 为无穷大或NaN时。
 * x == x 和 x != x 与 1 和 0 不等同，当 x 为NaN时。
 * x < y 和 isless (x, y) 不等同，因为前者在操作数为NaN时设置一个粘性异常标志（请参阅异常标志），而后者不会影响该标志。对于与关系运算符配对的其他isxxx函数也是如此。请参阅GNU C库参考手册中的FP比较函数。

选项 `-funsafe-math-optimizations` 启用了这些优化。

* 浮动算术异常标志

粘性异常标志记录特定条件的发生：一旦设置，它们将保持设置状态，直到程序明确清除它们。

这些条件包括无效操作数、除以零、不精确的结果（即需要四舍五入的结果）、下溢和上溢。一些扩展的浮点设计提供了几个额外的异常标志。
函数 `feclearexcept`、`feraiseexcept`、`fetestexcept`、`fegetexceptflags` 和
`fesetexceptflags` 提供了一个标准化的接口来访问这些标志。有关操作状态位的信息，请参阅GNU C库参考手册中的"状态位操作"。

其中一个重要用途是执行通常在浮点算术中被认为是精确的计算，但偶尔可能不精确，此时需要采取纠正措施。
您可以通过调用 `feclearexcept(FE_INEXACT)` 来清除不精确结果标志，进行计算，然后使用 `fetestexcept(FE_INEXACT)`
测试标志；如果标志未设置（没有进行四舍五入），那么该调用的结果为0，当进行四舍五入时（我们假设这意味着程序需要进行修正）结果为1。

* 精确浮点数算术

只要数字可以精确表示（分母是2的幂的分数），且中间结果不需要舍入，那么浮点算术就是精确的。很容易预测算术操作的结果需要多少位数字：

 * 具有相同指数的两个n位值的加法和减法最多需要n + 1位数字，但当指数不同时，可能需要更多位数字；

 * 两个n位值的乘法需要精确的2n位数字；

 * 尽管整数除法产生的商和余数都不超过n位数字，但浮点余数和平方根可能需要无限多位数字，而商可能需要比存储空间多得多的位数。

每当结果需要超过n位数字时，就需要进行舍入。

* 四舍五入

当浮点算术产生一个结果，无法完全容纳在正在使用的类型的尾数中时，就必须对该值进行舍入。
基本的算术操作，如加法、减法、乘法、除法和平方根，总是产生一个等价于准确结果（可能是无限精度）按照当前的舍入规则舍入到存储精度的结果。

舍入会设置 `FE_INEXACT` 异常标志（参见异常标志）。这使得程序可以确定发生了舍入。

舍入包括调整指数，使尾数返回到所需的基点对齐，然后根据当前的舍入规则将尾数压缩到固定的可用大小。

当前规则是在运行时从四个选项中选择的。以下是它们：

 * 最近舍入，如果遇到一半的情况则舍入到最接近的偶数；

 * 向上舍入，朝正无穷舍入；

 * 向下舍入，朝负无穷舍入；

 * 向零舍入。

在这四个舍入规则下，一个要舍入为四位数字结果的十进制值 -1.2345 会分别变为 -1.234、-1.234、-1.235 和 -1.234。

默认的舍入规则是最近舍入，因为它具有最小的偏差，并且产生最低的平均误差。当真实结果恰好处于两个可表示的机器数之间时，
结果会舍入为以偶数数字结尾的那一个。

向零舍入规则在许多早期计算机设计中很常见，因为它最容易实现：它只需要对所有额外的位进行静默截断。

另外两个规则，向上舍入和向下舍入，对于实现区间算术至关重要，其中每个算术操作产生下限和上限，这些下限和上限被保证包围精确结果。

有关获取和设置当前舍入模式的详细信息，请参阅"舍入控制"。

* 舍入问题

默认的IEEE 754舍入模式最小化了误差，大多数常规计算不应该因舍入而积累严重的误差。

当然，你可以构造一些例子来证明这一点。以下是一个例子：迭代计算一个数的平方根，然后尝试通过重复平方来恢复原始值。

#+begin_src c
#include <stdio.h>
#include <math.h>

int main (void)
{
  double x = 100.0;
  double y;
  for (n = 10; n <= 100; n += 10)
    {
      y = x;
      for (k = 0; k < n; ++k) y = sqrt (y);
      for (k = 0; k < n; ++k) y *= y;
      printf ("n = %3d; x = %.0f\ty = %.6f\n", n, x, y);
    }
  return 0;
}
#+end_src

输出如下：

#+begin_src c
n =  10; x = 100        y = 100.000000
n =  20; x = 100        y = 100.000000
n =  30; x = 100        y = 99.999977
n =  40; x = 100        y = 99.981025
n =  50; x = 100        y = 90.017127
n =  60; x = 100        y = 1.000000
n =  70; x = 100        y = 1.000000
n =  80; x = 100        y = 1.000000
n =  90; x = 100        y = 1.000000
n = 100; x = 100        y = 1.000000
#+end_src

经过50次迭代，y仅有一位正确的数字，而不久后，将没有正确的数字。

* 精度损失

在浮点计算中，更严重的误差来源之一是从几乎相等的值相减中导致的精度损失。
这意味着结果的尾数中的位数比该值的大小允许的位数要少。如果被相减的值足够接近但仍不相等，
单次减法可能会抹掉所有正确的数字，可能污染所有未来的计算。

浮点计算有时可以精心设计，以确保不会发生有精度损失，例如求和一系列所有项具有相同符号的级数。
例如，三角函数和双曲正弦的泰勒级数展开具有相同幅度的项，一般形式为 x**(2*n + 1) / (2*n + 1)!。
然而，三角函数正弦级数中的项在符号上交替，而双曲正弦级数中的项都是正数。
以下是两个小程序的输出，它们对sin(x)级数的前k项求和，并将计算得到的和与已知精确的库函数进行比较：

#+begin_src c
x = 10      k = 51
s (x)   = -0.544_021_110_889_270
sin (x) = -0.544_021_110_889_370

x = 20      k = 81
s (x)   = 0.912_945_250_749_573
sin (x) = 0.912_945_250_727_628

x = 30      k = 109
s (x)   = -0.987_813_746_058_855
sin (x) = -0.988_031_624_092_862

x = 40      k = 137
s (x)   = 0.617_400_430_980_474
sin (x) = 0.745_113_160_479_349

x = 50      k = 159
s (x)   = 57_105.187_673_745_720_532
sin (x) = -0.262_374_853_703_929

// sinh(x) series summation with positive signs
// with k terms needed to converge to machine precision

x = 10      k = 47
t (x)    = 1.101_323_287_470_340e+04
sinh (x) = 1.101_323_287_470_339e+04

x = 20      k = 69
t (x)    = 2.425_825_977_048_951e+08
sinh (x) = 2.425_825_977_048_951e+08

x = 30      k = 87
t (x)    = 5.343_237_290_762_229e+12
sinh (x) = 5.343_237_290_762_231e+12

x = 40      k = 105
t (x)    = 1.176_926_334_185_100e+17
sinh (x) = 1.176_926_334_185_100e+17

x = 50      k = 121
t (x)    = 2.592_352_764_293_534e+21
sinh (x) = 2.592_352_764_293_536e+21
#+end_src

我们已经在数字中添加了下划线以增强可读性。

正项的sinh(x)级数可以被求和到高精度。相比之下，sin(x)级数会受到逐渐增加的有效数字损失的影响，
因此当x = 30时，只有两位正确的数字保留下来。不久后，所有数字都是错误的，答案毫无意义。

数值编程中的一个重要技能是识别何时有效数字损失可能会影响计算，并修改算法以减少这个问题。
有时，唯一可行的方法是以更高的中间精度进行计算，这就是扩展类型如long double之类的重要性所在。

* 融合乘法-加法

1990年，IBM引入了POWER架构时，CPU提供了一条之前未知的指令，即融合乘法-加法（FMA）。
它计算值x * y + z，通过精确的双长度乘积，然后进行一次舍入后的加法。在数值计算中，经常需要一对乘法和加法操作，FMA非常适合这种需求。

在POWER架构中，有两个专用寄存器用于存储永久值0.0和1.0，而普通的乘法和加法指令只是FMA的包装器，分别计算x * y + 0.0和x * 1.0 + z。

在早期，FMA的主要优点似乎是以一个操作的价格获得两个浮点操作，几乎将某些算法的性能翻倍。
然而，自那时以来，数值分析家已经展示了FMA在显著提高精度方面的许多用途。我们将在下一节讨论其中一个最重要的用途。

自那时以来，一些其他架构已经包括了FMA，并且大多数提供了相关操作x * y - z（FMS）、-x * y + z（FNMA）和-x * y - z（FNMS）的变种。

函数`fmaf`、`fma`和`fmal`实现了浮点、双精度和长双精度数据类型的融合乘法-加法。
在软件中正确实现FMA是困难的，一些系统似乎提供了这些函数，但不满足单次舍入的要求。
随着越来越多的程序员使用FMA操作，以及更多的CPU在硬件中提供FMA，这种情况应该会发生改变。

使用`-ffp-contract=fast`选项允许生成FMA指令，或使用`-ffp-contract=off`选项禁止它。

* 错误恢复

当两个数字通过四种基本运算之一相结合时，结果通常需要舍入到存储精度。为了进行准确的计算，
我们希望能够恢复舍入误差。在历史上的浮点设计中，要在可移植的方式下实现这一点是很困难的，
但现在由于IEEE 754算术标准的普遍采用的，这项工作变得容易得多。

对于使用默认的最近舍入模式进行的加法，我们可以像这样确定一个总和的误差：

#+begin_src c
volatile double err, sum, tmp, x, y;

if (fabs (x) >= fabs (y))
  {
    sum = x + y;
    tmp = sum - x;
    err = y - tmp;
  }
else /* fabs (x) < fabs (y) */
  {
    sum = x + y;
    tmp = sum - y;
    err = x - tmp;
  }
#+end_src


现在，x + y 被表示为 sum + err。这个基本操作，在数值分析文献中通常被称为 twosum，
是跟踪和考虑舍入误差的第一个关键。

要确定减法的误差，只需交换+和-运算符。

在变量声明中使用了 volatile 限定符（请参阅 volatile），这会强制编译器将它们存储到内存中并从内存中检索它们，
并阻止编译器将 err = y - ((x + y) - x) 优化为 err = 0。

对于乘法，我们可以使用FMA操作（请参阅Fused Multiply-Add）来计算舍入误差，而无需进行幅值测试，如下所示：

#+begin_src c
volatile double err, prod, x, y;
prod = x * y;                /* rounded product */
err  = fma (x, y, -prod);    /* exact product = prod + err */
#+end_src

对于加法、减法和乘法，我们可以用两个值的概念上的总和来表示精确结果。
然而，除法、余数或平方根的精确结果可能需要无限数量的数字，所以我们最多只能近似表示它。
尽管如此，我们可以计算一个接近真实误差的误差项：它只是将误差值舍入到机器精度的值。

对于除法，你可以这样近似表示 x / y 为 quo + err：

#+begin_src c
volatile double err, quo, x, y;
quo = x / y;
err = fma (-quo, y, x) / y;
#+end_src

对于平方根，我们可以用 root + err 这种方式来近似表示 sqrt(x)：

#+begin_src c
  volatile double err, root, x;
  root = sqrt (x);
  err = fma (-root, root, x) / (root + root);
#+end_src

有了IEEE 754算术标准提供的可靠和可预测的浮点设计，我们现在拥有了追踪五种基本浮点操作中的误差所需的工具，
我们可以有效地模拟在两倍工作精度中进行计算，这有时足以消除几乎所有的算术错误痕迹。

* 精确浮点常数

自数字计算机诞生以来，数值程序员一直面临的一个令人沮丧的问题是无法在其程序中精确指定数字。
在早期的十进制机器上，这并不是问题：您可以编写一个常量1e-30，并确信该精确值将在浮点操作中使用。
然而，当硬件使用的基数不是10时，人为指定的数字必须转换为该基数，然后在输出时再次转换回来。
这两次基数转换很少是精确的，会引入不必要的舍入误差。

由于计算机通常以非十进制的基数表示数字，在转换过程中可能会出现舍入误差。
在C语言中，可以使用十六进制浮点常数来解决这个问题。例如，+0x1.fffffcp-1 是最接近但小于1.0的IEEE 754 32位值。
尾数以十六进制分数表示，而2的幂则在指数字符p之后以十进制书写（传统的指数字符e不可能使用，因为它是一个十六进制数字）。

在printf、scanf以及相关函数中，您可以使用'%a'和'%A'格式说明符来写入和读取十六进制浮点值。
'%a'使用小写字母编写它们，而'%A'则使用大写字母编写它们。例如，以下代码可以复制我们的示例数字：

#+begin_src c
printf ("%a\n", 1.0 - pow (2.0, -23));
    -| 0x1.fffffcp-1
#+end_src

类似地，strtod系列函数也被扩展以识别那种新格式的数字。

如果您希望在不同计算机上的C程序之间传输浮点数时确保精确的数据表示，那么十六进制常数是一个最佳选择。

* 处理无穷大

正如我们之前注意到的，IEEE 754计算模型并不是在发生异常情况时停止程序。
它通过设置粘性异常标志或产生带有特殊值Infinity和QNaN的结果来注意异常值或条件。
在本节中，我们讨论Infinity；有关另一个情况NaN 的处理，请参见Handling NaN。

在GNU C中，您可以通过以下方式在软件中创建负无穷大的值：

#+begin_src c
double x;

x = -1.0 / 0.0;
#+end_src


GNU C提供了__builtin_inf、__builtin_inff和__builtin_infl宏，
而GNU C库提供了INFINITY宏，所有这些宏都是正无穷大的编译时常数。

GNU C还提供了用于测试是否为无穷大的标准函数：isinf(x)如果参数是有符号无穷大则返回1，否则返回0。

GNU C提供了__builtin_inf、__builtin_inff和__builtin_infl宏，而GNU C库提供了INFINITY宏，
所有这些宏都是正无穷大的编译时常数。

GNU C还提供了用于测试是否为无穷大的标准函数：isinf(x)如果参数是有符号无穷大则返回1，否则返回0。

无穷大可以进行比较，所有相同符号的无穷大都是相等的：在IEEE 754算术中，没有不同类型的无穷大的概念，
就像在数学的某些领域中那样。正无穷大大于任何有限值，而负无穷大小于任何有限值。

无穷大在加法、减法、乘法和平方根中传播，但在除法中它们消失，因为有规定有限数值 / 无穷大等于0.0。
因此，在产生无穷大的中间计算中发生的溢出可能会在最终结果中被注意到。
程序员可以决定是否期望和接受这种溢出，或者代码可能存在错误，或者需要以更高的精度运行，
或者需要重新设计以避免产生无穷大。

* 处理 NaN

NaN不是数字：它们代表来自产生未定义结果的计算的值。它们具有一种独特的特性，
使它们与任何其他浮点值都不同：它们与一切都不相等，包括自己！因此，您可以像这样编写一个测试来检测NaN：

#+begin_src c
if (x != x)
  printf ("x is a NaN\n");
#+end_src

这个测试在GNU C中可以工作，但有些编译器可能会将该测试表达式评估为false，而没有正确检查NaN值。
一个更具可移植性的测试NaN的方法是使用math.h中声明的isnan函数：

#+begin_src c
if (isnan (x))
  printf ("x is a NaN\n");
#+end_src

请查看《GNU C库参考手册》中的"浮点类别（Floating Point Classes）"。

NaN的一个重要用途是标记缺失数据。例如，在统计学中，必须从计算中排除这些数据。
使用任何特定的有限值来表示缺失数据最终会与真实数据产生冲突，而这种数据永远不可能是NaN，
因此它是一个理想的标记。处理可能包含空白的数据集的函数可以编写以测试和忽略NaN值。

在计算中很容易生成NaN：评估0.0 / 0.0是最常见的方法，但Infinity - Infinity、Infinity / Infinity和sqrt(-1.0)也可以工作。
接收越界参数的函数可以选择返回存储的NaN值，例如在math.h中定义的NAN宏，但这不会设置无效操作异常标志，
并且可能会误导一些程序。

像Infinity一样，NaN在计算中传播，但它们更加"粘性"，因为它们在除法中永远不会消失。
因此，一旦NaN出现在一系列数值操作中，几乎可以肯定它会弹出到最终的结果中。
程序员必须决定是否这是预期的行为，或者是否存在需要修复的编码或算法错误。

通常情况下，当函数接收到NaN参数时，它通常会返回NaN。然而，有一些例外情况需要注意，
因为它们违反了NaN始终传播的规则：

 * pow (x, 0.0) 总是返回1.0，即使 x 是 0.0、Infinity 或 NaN 也是如此。

 * pow (1, y) 总是返回1，即使 y 是 NaN 也是如此。

 * hypot (INFINITY, y) 和 hypot (-INFINITY, y) 都总是返回 INFINITY，即使 y 是 NaN 也是如此。

 * 如果 fmax (x, y) 或 fmin (x, y) 的参数中只有一个是 NaN，它将返回另一个参数。
   如果两个参数都是 NaN，它会返回一个 NaN，但没有规定它来自哪个参数：它可能是 x，也可能是 y，
   或者是其他某个 quiet NaN。

NaNs还用于数学库函数的返回值，其中结果在实际算术中无法表示，或在数学上是未定义的或不确定的，
例如sqrt(-1.0)和sin(Infinity)。然而，请注意，仅仅是太大而无法表示的结果应该总是产生Infinity，
例如exp(1000.0)（太大了）和exp(Infinity)（真正的无穷大）。

* 有符号0

零的符号是重要的，因为它记录了一个值的产生，这个值太小而无法表示，但它可以来自负轴或正轴。
在复数算术中（参见复数算术），这些微妙的区别对于正确处理分支切割非常重要。

关于有符号零的关键点在于，在比较中，它们的符号并不重要：0.0 == -0.0 必须始终评估为1（真）。
然而，它们并不是相同的数字，而在C代码中，-0.0 表示负零。

* 按基数的幂进行缩放

我们在本章中已经多次讨论了舍入误差，但重要的是要记住，当结果所需的位数不超过指数和尾数位数可以表示的范围时，
这些结果是精确的。

其中一种特别有用的精确操作是按基数的幂进行缩放。虽然原则上可以使用如下代码来进行这种操作：

#+begin_src c
y = x * pow (2.0, (double)k);   /* Undesirable scaling: avoid! */
#+end_src

这并不建议，因为它依赖于数学库中幂函数的质量，而幂函数恰好是C数学库中最难精确计算的函数之一。
在许多系统上，pow返回的值可能接近某个二的幂，但略有不同，因此随后的乘法会引入舍入误差。

正确且速度最快的缩放方式要么是通过传统的C库函数，要么是通过它的C99等效函数：

#+begin_src c
y = ldexp (x, k);            /* Traditional pre-C99 style. */
y = scalbn (x, k);           /* C99 style. */
#+end_src

这两个函数都返回 x * 2**k。请参阅《GNU C库参考手册》中的"归一化函数（Normalization Functions）"。

* 舍入控制

以下是如何在运行时指定舍入模式的描述。系统头文件fenv.h提供了这些函数的原型。
请参阅《GNU C库参考手册》中的"舍入（Rounding）"部分。

该头文件还提供了四种舍入模式的常量名称：FE_DOWNWARD、FE_TONEAREST、FE_TOWARDZERO和FE_UPWARD。

函数fegetround检查并返回当前的舍入模式。在具有IEEE 754浮点的平台上，该值将始终等于这四个常量中的一个。
在其他平台上，它可能返回一个负值。函数fesetround设置当前的舍入模式。

更改舍入模式可能会很慢，因此有用的是尽量减少更改的次数。对于区间算术，
每个操作似乎需要三次更改，但实际上只需要两次，因为我们可以编写如下示例中的代码来对两个实数进行区间加法：

#+begin_src c
{
  struct interval_double
    {
      double hi, lo;
    } v;
  volatile double x, y;
  int rule;

  rule = fegetround ();

  if (fesetround (FE_UPWARD) == 0)
    {
      v.hi = x + y;
      v.lo = -(-x - y);
    }
  else
    fatal ("ERROR: failed to change rounding rule");

  if (fesetround (rule) != 0)
    fatal ("ERROR: failed to restore rounding rule");
}
#+end_src

在x86平台上，使用volatile限定符（参见volatile）对于防止优化编译器生成相同的边界值非常重要。

* 机器精度

在任何浮点系统中，了解三个特别重要的属性是很重要的：基数（指数指定的幂次数）、
精度（尾数中的数字位数）和范围（最大正数和最小负数之间的差值）。在指数和尾数之间分配比特位决定了这些问题的答案。

精度的度量是回答以下问题的答案：对于1.0，可以添加的最小数是多少，以使总和与1.0不同？这个数称为机器ε（epsilon）。

我们可以像这样定义float、double和long double所需的机器精度常量：

#+begin_src c
static const float  epsf = 0x1p-23;  /* about 1.192e-07 */
static const double eps  = 0x1p-52;  /* about 2.220e-16 */
static const long double epsl = 0x1p-63;  /* about 1.084e-19 */
#+end_src


除了十六进制常数之外，我们还可以使用标准C宏FLT_EPSILON、DBL_EPSILON和LDBL_EPSILON。

能够在运行时计算机器精度（epsilon）是很有用的，我们可以通过将常数1.0替换为用户提供的值来轻松地将操作推广为通用操作：

#+begin_src c
double
macheps (double x)
{ /* Return machine epsilon for x,  */
      such that x + macheps (x) > x.  */
  static const double base = 2.0;
  double eps;

  if (isnan (x))
      eps = x;
  else
    {
      eps = (x == 0.0) ? 1.0 : x;

      while ((x + eps / base) != x)
          eps /= base;          /* Always exact!  */
    }

  return (eps);
}
#+end_src

如果我们用从0到10的参数以及Infinity和NaN调用该函数，并以十六进制打印返回的值，我们会得到如下输出：

#+begin_src c
macheps (  0) = 0x1.0000000000000p-1074
macheps (  1) = 0x1.0000000000000p-52
macheps (  2) = 0x1.0000000000000p-51
macheps (  3) = 0x1.8000000000000p-52
macheps (  4) = 0x1.0000000000000p-50
macheps (  5) = 0x1.4000000000000p-51
macheps (  6) = 0x1.8000000000000p-51
macheps (  7) = 0x1.c000000000000p-51
macheps (  8) = 0x1.0000000000000p-49
macheps (  9) = 0x1.2000000000000p-50
macheps ( 10) = 0x1.4000000000000p-50
macheps (Inf) = infinity
macheps (NaN) = nan
#+end_src

请注意，`macheps` 函数中对 NaN 进行了特殊测试，以防止无限循环。

我们的代码对参数值是否为零单独使用了一个条件，以避免得到零的返回值。在这种情况下，
返回的值是可表示的最小浮点数，即亚标准值2**(-1074)，约为4.941e-324。

对于Infinity，不需要进行特殊测试，因为eps缩减循环在第一次迭代时终止。

我们这里的 `macheps` 函数假定了二进制浮点；某些体系结构可能有所不同。

C库中包括一些相关的函数，也可以用于在运行时确定机器ε（epsilon）：

#+begin_src c
#include <math.h>           /* Include for these prototypes. */

double      nextafter  (double x, double y);
float       nextafterf (float x, float y);
long double nextafterl (long double x, long double y);
#+end_src

这些函数返回在方向y上最接近x的机器数。例如，nextafter(1.0, 2.0)
产生的结果与 1.0 + macheps(1.0) 和 1.0 + DBL_EPSILON 相同。
请参阅《GNU C库参考手册》中的 "FP Bit Twiddling" 部分。

重要的是要知道，机器ε（epsilon）并不在所有数字周围对称。在规范化改变指数的边界上，
x下面的ε小于x上面的ε，差异因子为1 / 基数。例如，macheps(1.0) 返回 +0x1p-52，
而macheps(-1.0) 返回 +0x1p-53。一些作者通过称它们为正负或大小机器ε来区分这些情况。您可以像这样计算它们的值：

#+begin_src c
eps_neg = 1.0 - nextafter (1.0, -1.0);
eps_pos = nextafter (1.0, +2.0) - 1.0;
#+end_src

如果x是一个变量，因此在编译时无法确定其值，那么您可以将字面值y值替换为-either -inf() 或 +inf()，就像这样：

#+begin_src c
eps_neg = x - nextafter (x, -inf ());
eps_pos = nextafter (x, +inf() - x);
#+end_src

在这种情况下，如果x是Infinity，那么nextafter函数如果x等于y，它们会返回y。
然后，我们的两个赋值会分别为eps_neg生成+0x1.fffffffffffffp+1023（约为1.798e+308），
而为eps_pos生成Infinity。因此，调用nextafter(INFINITY, -INFINITY)可用于查找最大可表示的有限数，
而调用nextafter(0.0, 1.0)可用于找到最小可表示的数（在这里是0x1p-1074，约为4.491e-324，
我们之前从macheps(0.0)的输出中看到过这个数字）。

* 复数算数

我们已经讨论了定义和引用复数（请参见复杂数据类型）。这里需要讨论的重要问题是，
对于没有广泛数值计算和数学复数运算经验的程序员来说，一些问题可能不太明显。

第一个重要点是，与实数算术不同，复数算术中的有效数字丢失危险是普遍存在的，
并影响到所有基本操作以及几乎所有数学库函数。要理解为什么会这样，回想一下复数乘法和除法的规则：

#+begin_src c
a = u + I*v              /* First operand. */
b = x + I*y              /* Second operand. */

prod = a * b
     = (u + I*v) * (x + I*y)
     = (u * x - v * y) + I*(v * x + u * y)

quo  = a / b
     = (u + I*v) / (x + I*y)
     = [(u + I*v) * (x - I*y)] / [(x + I*y) * (x - I*y)]
     = [(u * x + v * y) + I*(v * x - u * y)] / (x**2 + y**2)
#+end_src

对于这些公式，有四个关键观察点：

 * 右侧的乘法引入了过早下溢或上溢的可能性；

 * 这些乘积必须精确到两倍的工作精度；

 * 右侧总是有一次减法可能会导致严重的有效数字丢失；

 * 复数乘法有高达六个舍入误差，复数除法有十个舍入误差。

还需要仔细研究的另一个问题是复数算术中许多函数都具有分支切。您可以将具有复数参数的函数
f (z) 视为 f (x + I*y)，因此，它定义了复平面上点 (x, y) 与表面上的一个高度值之间的关系。
分支切看起来像是表面上的一处撕裂，因此从一侧接近切会产生一个特定的值，而从另一侧接近则会产生一个完全不同的值。
需要非常小心地处理分支切，即使小的数值误差也可能将结果从一侧推到另一侧，从而根本改变了返回值。
正如我们之前提到的，正确处理零的符号对于在分支切附近进行计算至关重要。

对于需要复数算术的程序员，我们可以提供的最好建议是始终使用可用的最高精度，然后仔细检查测试计算的结果，
以评估计算结果的可能精度。很容易提供实部和虚部的测试值，
其中复数算术中的所有五个基本操作和几乎所有复杂数学函数都失去了所有有效数字，无法产生一个正确的数字。

尽管复数算术使一些编程任务变得更容易，但从数值上讲，重新设计算法以在实数算术中执行可能更可取。
这在矩阵代数中通常是可能的。

如果不需要某些边界检查，GNU C可以对复数乘法和除法进行代码优化。命令行选项 -fcx-limited-range 告诉编译器，
在执行复数除法时不需要范围缩减步骤，也不需要检查复数乘法或除法是否会导致值 Nan + I*NaN。
默认情况下，这些检查是启用的。您可以使用 -fno-cx-limited-range 选项显式禁用它们。

* 往复进制转换

大多数数值程序涉及在计算机表示的二进制浮点数和程序员输入和处理的基十浮点数之间进行转换。
可能不太明显的是，每种表示所需的二进制比特数与十进制数字的数量。
考虑以下表格，显示了在给定位数的情况下可以表示的十进制数字数量，以及反之亦然：

#+begin_src c
binary in	24	53	64	113	237
decimal out	9	17	21	36	73
decimal in	7	16	34	70
binary out	25	55	114	234
#+end_src

我们可以使用以下两个函数计算表格中的数字：

#+begin_src c
int
matula(int nbits)
{   /* Return output decimal digits needed for nbits-bits input. */
    return ((int)ceil((double)nbits / log2(10.0) + 1.0));
}

int
goldberg(int ndec)
{   /* Return output bits needed for ndec-digits input. */
    return ((int)ceil((double)ndec / log10(2.0) + 1.0));
}
#+end_src

从这些数字中可以得出一个重要观察结果，那就是在相同的存储大小内，
我们无法实现十进制和二进制格式之间的正确往返转换！例如，
我们需要25位来表示32位十进制格式中的7位值，但二进制格式只有24位可用。对于其他每一对转换，类似的观察都成立。

一般的输入/输出进制转换问题非常复杂，直到1990年才公开知晓解决方法，
这些解决方法在本章末尾附近的两篇论文中列出。对于128位格式，最坏情况需要超过11,500位的十进制精度，
以确保在二进制到十进制的转换中正确舍入！

有关更多详细信息，请参阅Bennett Goldberg和David Matula的参考文献。

* 进阶阅读

浮点算术的主题比许多程序员似乎认为的要复杂得多，而且很少有编程语言的书籍在这个领域花费太多时间。
在本章中，我们尝试向读者介绍一些关键思想，并警告可能被轻视的陷阱，这些陷阱很快就会导致荒谬的结果。
有一些我们推荐的良好参考书，可以供进阶阅读，以及查找有关计算机算术的其他重要材料：

 * Paul H. Abbott and 15 others, Architecture and software support in IBM S/390 Parallel Enterprise Servers for IEEE Floating-Point arithmetic, IBM Journal of Research and Development 43(5/6) 723–760 (1999), https://doi.org/10.1147/rd.435.0723. This article gives a good description of IBM’s algorithm for exact decimal-to-binary conversion, complementing earlier ones by Clinger and others.

 * Nelson H. F. Beebe, The Mathematical-Function Computation Handbook: Programming Using the MathCW Portable Software Library, Springer (2017), ISBN 3-319-64109-3 (hardcover), 3-319-64110-7 (e-book) (xxxvi + 1114 pages), https://doi.org/10.1007/978-3-319-64110-2. This book describes portable implementations of a large superset of the mathematical functions available in many programming languages, extended to a future 256-bit format (70 decimal digits), for both binary and decimal floating point. It includes a substantial portion of the functions described in the famous NIST Handbook of Mathematical Functions, Cambridge (2018), ISBN 0-521-19225-0. See http://www.math.utah.edu/pub/mathcw for compilers and libraries.

 * William D. Clinger, How to Read Floating Point Numbers Accurately, ACM SIGPLAN Notices 25(6) 92–101 (June 1990), https://doi.org/10.1145/93548.93557. See also the papers by Steele & White.

 * William D. Clinger, Retrospective: How to read floating point numbers accurately, ACM SIGPLAN Notices 39(4) 360–371 (April 2004), http://doi.acm.org/10.1145/989393.989430. Reprint of 1990 paper, with additional commentary.

 * I. Bennett Goldberg, 27 Bits Are Not Enough For 8-Digit Accuracy, Communications of the ACM 10(2) 105–106 (February 1967), http://doi.acm.org/10.1145/363067.363112. This paper, and its companions by David Matula, address the base-conversion problem, and show that the naive formulas are wrong by one or two digits.

 * David Goldberg, What Every Computer Scientist Should Know About Floating-Point Arithmetic, ACM Computing Surveys 23(1) 5–58 (March 1991), corrigendum 23(3) 413 (September 1991), https://doi.org/10.1145/103162.103163. This paper has been widely distributed, and reissued in vendor programming-language documentation. It is well worth reading, and then rereading from time to time.

 * Norbert Juffa and Nelson H. F. Beebe, A Bibliography of Publications on Floating-Point Arithmetic, http://www.math.utah.edu/pub/tex/bib/fparith.bib. This is the largest known bibliography of publications about floating-point, and also integer, arithmetic. It is actively maintained, and in mid 2019, contains more than 6400 references to original research papers, reports, theses, books, and Web sites on the subject matter. It can be used to locate the latest research in the field, and the historical coverage dates back to a 1726 paper on signed-digit arithmetic, and an 1837 paper by Charles Babbage, the intellectual father of mechanical computers. The entries for the Abbott, Clinger, and Steele & White papers cited earlier contain pointers to several other important related papers on the base-conversion problem.

 * William Kahan, Branch Cuts for Complex Elementary Functions, or Much Ado About Nothing’s Sign Bit, (1987), http://people.freebsd.org/~das/kahan86branch.pdf. This Web document about the fine points of complex arithmetic also appears in the volume edited by A. Iserles and M. J. D. Powell, The State of the Art in Numerical Analysis: Proceedings of the Joint IMA/SIAM Conference on the State of the Art in Numerical Analysis held at the University of Birmingham, 14–18 April 1986, Oxford University Press (1987), ISBN 0-19-853614-3 (xiv + 719 pages). Its author is the famous chief architect of the IEEE 754 arithmetic system, and one of the world’s greatest experts in the field of floating-point arithmetic. An entire generation of his students at the University of California, Berkeley, have gone on to careers in academic and industry, spreading the knowledge of how to do floating-point arithmetic right.

 * Donald E. Knuth, A Simple Program Whose Proof Isn’t, in Beauty is our business: a birthday salute to Edsger W. Dijkstra, W. H. J. Feijen, A. J. M. van Gasteren, D. Gries, and J. Misra (eds.), Springer (1990), ISBN 1-4612-8792-8, https://doi.org/10.1007/978-1-4612-4476-9. This book chapter supplies a correctness proof of the decimal to binary, and binary to decimal, conversions in fixed-point arithmetic in the TeX typesetting system. The proof evaded its author for a dozen years.

 * David W. Matula, In-and-out conversions, Communications of the ACM 11(1) 57–50 (January 1968), https://doi.org/10.1145/362851.362887.

 * David W. Matula, The Base Conversion Theorem, Proceedings of the American Mathematical Society 19(3) 716–723 (June 1968). See also other papers here by this author, and by I. Bennett Goldberg.

 * David W. Matula, A Formalization of Floating-Point Numeric Base Conversion, IEEE Transactions on Computers C-19(8) 681–692 (August 1970), https://doi.org/10.1109/T-C.1970.223017.

 * Jean-Michel Muller and eight others, Handbook of Floating-Point Arithmetic, Birkhäuser-Boston (2010), ISBN 0-8176-4704-X (xxiii + 572 pages), https://doi.org/10.1007/978-0-8176-4704-9. This is a comprehensive treatise from a French team who are among the world’s greatest experts in floating-point arithmetic, and among the most prolific writers of research papers in that field. They have much to teach, and their book deserves a place on the shelves of every serious numerical programmer.

 * Jean-Michel Muller and eight others, Handbook of Floating-Point Arithmetic, Second edition, Birkhäuser-Boston (2018), ISBN 3-319-76525-6 (xxv + 627 pages), https://doi.org/10.1007/978-3-319-76526-6. This is a new edition of the preceding entry.

 * Michael Overton, Numerical Computing with IEEE Floating Point Arithmetic, Including One Theorem, One Rule of Thumb, and One Hundred and One Exercises, SIAM (2001), ISBN 0-89871-482-6 (xiv + 104 pages), http://www.ec-securehost.com/SIAM/ot76.html. This is a small volume that can be covered in a few hours.

 * Guy L. Steele Jr. and Jon L. White, How to Print Floating-Point Numbers Accurately, ACM SIGPLAN Notices 25(6) 112–126 (June 1990), https://doi.org/10.1145/93548.93559. See also the papers by Clinger.

 * Guy L. Steele Jr. and Jon L. White, Retrospective: How to Print Floating-Point Numbers Accurately, ACM SIGPLAN Notices 39(4) 372–389 (April 2004), http://doi.acm.org/10.1145/989393.989431. Reprint of 1990 paper, with additional commentary.

 * Pat H. Sterbenz, Floating Point Computation, Prentice-Hall (1974), ISBN 0-13-322495-3 (xiv + 316 pages). This often-cited book provides solid coverage of what floating-point arithmetic was like before the introduction of IEEE 754 arithmetic.
